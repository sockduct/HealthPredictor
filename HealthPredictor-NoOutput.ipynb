{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HealthPredictor\n",
    "<hr>\n",
    "\n",
    "## Midterm Jupyter Notebook, Group 1 - Healthcare\n",
    "## CIS-579-002, Introduction to Artificial Intelligence\n",
    "### Avinash Shete, Chandana Bhadravati Nagaraj, Jim Small, Ritesh Revansiddappa Honnalli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup environment/notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed libraries:\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data:\n",
    "# Note:  Using forward slashes (\"/\" versus \"\\\") so works on both Windows and Linux/macOS:\n",
    "data = './Data/chronickidneydisease.csv'\n",
    "df= pd.read_csv(data)\n",
    "\n",
    "# Explore first few rows:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First look at data/dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions (rows, columns) of dataframe:\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show overview of dataframe columns:\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show number of unique values per column:\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine descriptive statistics for each column - average, standard deviation, quartiles, and more:\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove id column:\n",
    "df.drop('id', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column names to make it more user-friendly:\n",
    "df.columns = ['age', 'blood_pressure', 'specific_gravity', 'albumin', 'sugar', 'red_blood_cells', 'pus_cell',\n",
    "              'pus_cell_clumps', 'bacteria', 'blood_glucose_random', 'blood_urea', 'serum_creatinine', 'sodium',\n",
    "              'potassium', 'hemoglobin', 'packed_cell_volume', 'white_blood_cell_count', 'red_blood_cell_count',\n",
    "              'hypertension', 'diabetes_mellitus', 'coronary_artery_disease', 'appetite', 'peda_edema',\n",
    "              'anemia', 'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again look at first few rows to see column name changes:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary statistics of numerical columns, including standard deviation and quartiles:\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show overview of dataframe columns:\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert relevant columns to numerical type:\n",
    "df['packed_cell_volume'] = pd.to_numeric(df['packed_cell_volume'], errors='coerce')\n",
    "df['white_blood_cell_count'] = pd.to_numeric(df['white_blood_cell_count'], errors='coerce')\n",
    "df['red_blood_cell_count'] = pd.to_numeric(df['red_blood_cell_count'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm changes - note the 3 columns data types are now floating point:\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect categorical and numerical columns:\n",
    "cat_cols = [col for col in df.columns if df[col].dtype == 'object']\n",
    "num_cols = [col for col in df.columns if df[col].dtype != 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review unique values in categorical columns to check for missing values (nans):\n",
    "def display_cols(cols, val_title='Values', op='unique'):\n",
    "    colsize = max(len(col) for col in cols)\n",
    "    trailing = int(colsize * 1.5)\n",
    "    print(f'{\"Column:\":>{colsize}} | {val_title}:')\n",
    "    print('-' * colsize, '|', '-' * trailing)\n",
    "    for col in sorted(cols):        \n",
    "        output = res if isinstance(res := getattr(df[col], op)(), int) else ', '.join(map(str, res)) \n",
    "        print(f'{col:>{colsize}} | {output}')\n",
    "\n",
    "display_cols(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra whitespace:\n",
    "for dfcol in ('diabetes_mellitus', 'coronary_artery_disease', 'class'):\n",
    "    df[dfcol] = df[dfcol].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-check:\n",
    "display_cols(cat_cols)\n",
    "\n",
    "# Note the nans - more cleanup to do..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visually Explore Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize numerical features distribution:\n",
    "plt.figure(figsize = (20, 15))\n",
    "\n",
    "for pn, column in enumerate(num_cols, 1):\n",
    "    if pn > 14:\n",
    "        break\n",
    "    ax = plt.subplot(3, 5, pn)\n",
    "    sns.distplot(df[column])\n",
    "    plt.xlabel(column)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize categorical column data distribution:\n",
    "plt.figure(figsize = (20, 15))\n",
    "\n",
    "for i, column in enumerate(cat_cols, 1):\n",
    "    if i > 11:\n",
    "        break\n",
    "    ax = plt.subplot(3, 4, i)\n",
    "    sns.countplot(df[column], palette = 'rocket')\n",
    "    plt.xlabel(column)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remap values - patients with Chronic Kidney Disease = 0, without = 1:\n",
    "df['class'] = df['class'].map({'ckd': 1, 'notckd': 0})\n",
    "df['class'] = pd.to_numeric(df['class'], errors='coerce')\n",
    "# Note:  Doing this after plotting as the plot looks better before converting it to a numeric column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of data:\n",
    "plt.figure(figsize = (15, 8))\n",
    "\n",
    "# Note:  Had to add numeric_only=True argument or errors out as there are non-numeric values:\n",
    "sns.heatmap(df.corr(numeric_only=True), annot = True, linewidths = 2, linecolor = 'lightgrey')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show data columns:\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Data Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to plot data:\n",
    "\n",
    "# Create a violin plot to contrast each column for those with and without CKD\n",
    "# Include a box plot within the violin plot (box=True)\n",
    "def violin(col):\n",
    "    fig = px.violin(df, y=col, x='class', color='class', box=True, template='plotly_dark',\n",
    "                    color_discrete_map={0: '#636EFA', 1: '#EF553B'})\n",
    "    fig.update_layout(legend_traceorder='reversed')\n",
    "    return fig.show()\n",
    "\n",
    "# Create a Kernel Density Estimation plot contrasting those with and without CKD\n",
    "# Allows visualizing the probability density function (PDF) of a continuous variable\n",
    "# In other words - this visually shows the distribution of the column data\n",
    "def kde(col):\n",
    "    grid = sns.FacetGrid(df, hue='class', height=6, aspect=2)\n",
    "    grid.map(sns.kdeplot, col)\n",
    "    grid.add_legend()\n",
    "\n",
    "# Create a scatter plot contrasting pairs of columns for those with and without CKD\n",
    "# This allows visualizing the relationship and correlation between pairs of columns\n",
    "# while simultaneously differentiating (via color) those with and without CKD\n",
    "def scatter(col1, col2):\n",
    "    fig = px.scatter(df, x=col1, y=col2, color='class', template='plotly_dark',\n",
    "                     color_discrete_map={0: '#636EFA', 1: '#EF553B'})\n",
    "    fig.update_layout(legend_traceorder='reversed')\n",
    "    return fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violin('red_blood_cell_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde('red_blood_cell_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violin('white_blood_cell_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde('white_blood_cell_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violin('packed_cell_volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde('packed_cell_volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violin('hemoglobin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde('hemoglobin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violin('albumin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde('albumin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violin('blood_glucose_random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde('blood_glucose_random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violin('sodium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde('sodium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violin('blood_urea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde('blood_urea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violin('specific_gravity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde('specific_gravity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter('hemoglobin', 'packed_cell_volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter('red_blood_cell_count', 'packed_cell_volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter('red_blood_cell_count', 'albumin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter('sugar', 'blood_glucose_random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter('packed_cell_volume','blood_urea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(df, x=\"specific_gravity\", y=\"packed_cell_volume\", color='class', barmode='group', template = 'plotly_dark', height = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(df, x=\"specific_gravity\", y=\"albumin\", color='class', barmode='group', template = 'plotly_dark', height = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(df, x=\"blood_pressure\", y=\"packed_cell_volume\", color='class', barmode='group', template = 'plotly_dark', height = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(df, x=\"blood_pressure\", y=\"hemoglobin\", color='class', barmode='group', template = 'plotly_dark', height = 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values:\n",
    "df.isna().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cat_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For filling null values, we will use two methods, random sampling for higher null values\n",
    "# and mean/mode sampling for lower null values:\n",
    "def random_value_imputation(feature):\n",
    "    random_sample = df[feature].dropna().sample(df[feature].isna().sum())\n",
    "    random_sample.index = df[df[feature].isnull()].index\n",
    "    df.loc[df[feature].isnull(), feature] = random_sample\n",
    "    \n",
    "def impute_mode(feature):\n",
    "    mode = df[feature].mode()[0]\n",
    "    df[feature] = df[feature].fillna(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling num_cols null values using random sampling method:\n",
    "for col in num_cols:\n",
    "    random_value_imputation(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling \"red_blood_cells\" and \"pus_cell\" using random sampling method\n",
    "# and rest of cat_cols using mode imputation:\n",
    "random_value_imputation('red_blood_cells')\n",
    "random_value_imputation('pus_cell')\n",
    "\n",
    "for col in cat_cols:\n",
    "    impute_mode(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cat_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cols(cat_cols, val_title='Categories', op='nunique')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in cat_cols:\n",
    "    df[col] = le.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = '5.0'></a>\n",
    "<p style = \"font-size : 45px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #f9b208; border-radius: 5px 5px;\"><strong>Model Building</strong></p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_col = [col for col in df.columns if col != 'class']\n",
    "dep_col = 'class'\n",
    "\n",
    "X = df[ind_col]\n",
    "y = df[dep_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display as display\n",
    "\n",
    "# Build confusion matrix results dataframe:\n",
    "def get_cm_results(cm):\n",
    "    # cm is the result of sklearn.metrics.confusion_matrix(y_test, classifier.predict(X_test))\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    data = [\n",
    "        {'Result': 'True Positive', 'Number': tp,\n",
    "         'Description': 'Actual occurrence, correctly predicted'},\n",
    "        {'Result': 'True Negative', 'Number': tn,\n",
    "         'Description': 'Non-occurrence, correctly predicted'},\n",
    "        {'Result': 'False Negative', 'Number': fn,\n",
    "         'Description': 'Actual occurrence, incorrectly predicted (Type II error)'},\n",
    "        {'Result': 'False Positive', 'Number': fp,\n",
    "         'Description': 'Non-occurrence, incorrectly predicted (Type I error)'},\n",
    "    ]\n",
    "    return pd.DataFrame(data).style.set_properties(\n",
    "        subset=['Description'], **{'text-align': 'left'}\n",
    "    ).hide(axis='index')\n",
    "\n",
    "\n",
    "# Build confusion matrix metrics dataframe:\n",
    "def get_cm_metrics(cm):\n",
    "    # cm is the result of sklearn.metrics.confusion_matrix(y_test, classifier.predict(X_test))\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    prec_val = tp/(tp + fp)\n",
    "    rec_val = tp/(tp + fn)\n",
    "    data = [\n",
    "        {'Metric': 'Accuracy', 'Value': (tp + tn)/(tp + tn + fp + fn),\n",
    "         'Description': 'How often is classifier correct'},\n",
    "        {'Metric': 'Precision', 'Value': prec_val,\n",
    "         'Description': 'How often is TP correctly predicted (% of correct positives)'},\n",
    "        {'Metric': 'Recall', 'Value': rec_val,\n",
    "         'Description': 'How often is actual occurrence correctly predicted'},\n",
    "        {'Metric': 'F1-Score', 'Value': (2 * prec_val * rec_val)/(prec_val + rec_val),\n",
    "         'Description': 'Account for both precision and recall using harmonic mean'},\n",
    "        {'Metric': 'Misclassification', 'Value': (fp + fn)/(tp + tn + fp + fn),\n",
    "         'Description': 'How often is classifier wrong'},\n",
    "        {'Metric': 'NPV', 'Value': tn/(tn + fn),\n",
    "         'Description': 'How often is TN correctly predicted (% of correct negatives)'},\n",
    "        {'Metric': 'FPR', 'Value': fp/(tn + fp),\n",
    "         'Description': 'How often is non-occurrence falsely predicted'},\n",
    "        {'Metric': 'Specificity', 'Value': tn/(tn + fp),\n",
    "         'Description': 'How often is actual non-occurrence correctly predicted'},\n",
    "        {'Metric': 'Prevalence', 'Value': (fn + tp)/(tp + tn + fp + fn),\n",
    "         'Description': 'How often does actually occurrence occur in sample'},\n",
    "    ]\n",
    "    return pd.DataFrame(data).style.set_properties(\n",
    "        subset=['Description'], **{'text-align': 'left'}\n",
    "    ).format({'Value': '{:.2%}'}).hide(axis='index')\n",
    "\n",
    "# Plot confusion matrix heatmap:\n",
    "def cm_heatmap(cm):\n",
    "    classes = ['No CKD', 'CKD']\n",
    "    df_cm = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "    \n",
    "    # Flip horizontally and vertically\n",
    "    df_cm = df_cm.iloc[::-1, ::-1]\n",
    "    \n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(df_cm, annot=True, fmt='d', cmap='coolwarm_r',\n",
    "                linewidths=0.5, cbar_kws={'label': 'Count'})\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix Heatmap')\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = '5.2'></a>\n",
    "<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>Decision Tree Classifier</strong></p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy score, confusion matrix and classification report of decision tree:\n",
    "dtc_acc = accuracy_score(y_test, dtc.predict(X_test))\n",
    "\n",
    "print(f\"Training Accuracy of Decision Tree Classifier is {accuracy_score(y_train, dtc.predict(X_train))}\")\n",
    "print(f\"Test Accuracy of Decision Tree Classifier is {dtc_acc} \\n\")\n",
    "\n",
    "cm = confusion_matrix(y_test, dtc.predict(X_test))\n",
    "print(f\"Confusion Matrix :- \\n{cm}\\n\")\n",
    "print(f\"Classification Report :- \\n {classification_report(y_test, dtc.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix heatmap:\n",
    "cm_heatmap(cm)\n",
    "\n",
    "# Show classifier results and metrics:\n",
    "display(get_cm_results(cm))\n",
    "display(get_cm_metrics(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter tuning of decision tree:\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_param = {\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'max_depth' : [3, 5, 7, 10],\n",
    "    'splitter' : ['best', 'random'],\n",
    "    'min_samples_leaf' : [1, 2, 3, 5, 7],\n",
    "    'min_samples_split' : [1, 2, 3, 5, 7],\n",
    "    'max_features' : ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_search_dtc = GridSearchCV(dtc, grid_param, cv = 5, n_jobs = -1, verbose = 1)\n",
    "grid_search_dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters and best score:\n",
    "print(grid_search_dtc.best_params_)\n",
    "print(grid_search_dtc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best estimator:\n",
    "dtc = grid_search_dtc.best_estimator_\n",
    "\n",
    "# Accuracy score, confusion matrix and classification report of decision tree\n",
    "dtc_acc = accuracy_score(y_test, dtc.predict(X_test))\n",
    "\n",
    "print(f\"Training Accuracy of Decision Tree Classifier is {accuracy_score(y_train, dtc.predict(X_train))}\")\n",
    "print(f\"Test Accuracy of Decision Tree Classifier is {dtc_acc} \\n\")\n",
    "\n",
    "cm = confusion_matrix(y_test, dtc.predict(X_test))\n",
    "print(f\"Confusion Matrix :- \\n{cm}\\n\")\n",
    "print(f\"Classification Report :- \\n {classification_report(y_test, dtc.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix heatmap:\n",
    "cm_heatmap(cm)\n",
    "\n",
    "# Show classifier results and metrics:\n",
    "display(get_cm_results(cm))\n",
    "display(get_cm_metrics(cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = '5.3'></a>\n",
    "<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>Random Forest Classifier</strong></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Note:  The default for max_features changed from 'auto' to 'sqrt', updating:\n",
    "rd_clf = RandomForestClassifier(criterion = 'entropy', max_depth = 11, max_features = 'sqrt', min_samples_leaf = 2, min_samples_split = 3, n_estimators = 130)\n",
    "rd_clf.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy score, confusion matrix and classification report of random forest:\n",
    "rd_clf_acc = accuracy_score(y_test, rd_clf.predict(X_test))\n",
    "\n",
    "print(f\"Training Accuracy of Random Forest Classifier is {accuracy_score(y_train, rd_clf.predict(X_train))}\")\n",
    "print(f\"Test Accuracy of Random Forest Classifier is {rd_clf_acc} \\n\")\n",
    "\n",
    "cm = confusion_matrix(y_test, rd_clf.predict(X_test))\n",
    "print(f\"Confusion Matrix :- \\n{cm}\\n\")\n",
    "print(f\"Classification Report :- \\n {classification_report(y_test, rd_clf.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix heatmap:\n",
    "cm_heatmap(cm)\n",
    "\n",
    "# Show classifier results and metrics:\n",
    "display(get_cm_results(cm))\n",
    "display(get_cm_metrics(cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = '6.0'></a>\n",
    "<p style = \"font-size : 35px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #f9b208; border-radius: 5px 5px;\"><strong>Models Comparison</strong></p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model' : ['Decision Tree Classifier', 'Random Forest Classifier'],\n",
    "    'Score' : [dtc_acc, rd_clf_acc]\n",
    "})\n",
    "\n",
    "models.sort_values(by = 'Score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(data_frame = models, x = 'Score', y = 'Model', color = 'Score', template = 'plotly_dark', \n",
    "       title = 'Models Comparison')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select random forest classifier - more reliable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 Features:\n",
    "feature_scores=pd.DataFrame(rd_clf.feature_importances_,columns=['Score'],index=X_train.columns).sort_values(by='Score',ascending=False)\n",
    "top10_feature = feature_scores.nlargest(n=10, columns=['Score'])\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "g = sns.barplot(x=top10_feature.index, y=top10_feature['Score'])\n",
    "p = plt.title('Top 10 Features with Random Forest')\n",
    "p = plt.xlabel('Feature name')\n",
    "p = plt.ylabel('Random Forest score')\n",
    "p = g.set_xticklabels(g.get_xticklabels(), horizontalalignment='right', rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_feature.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prune columns not in top 10:\n",
    "for ele in X.columns:\n",
    "    if ele not in top10_feature.index:\n",
    "        X = X.drop(ele, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train[['specific_gravity', 'hemoglobin', 'serum_creatinine', 'albumin',\n",
    "       'packed_cell_volume', 'diabetes_mellitus', 'hypertension',\n",
    "       'blood_glucose_random', 'red_blood_cell_count', 'blood_urea']]\n",
    "X_test=X_test[['specific_gravity', 'hemoglobin', 'serum_creatinine', 'albumin',\n",
    "       'packed_cell_volume', 'diabetes_mellitus', 'hypertension',\n",
    "       'blood_glucose_random', 'red_blood_cell_count', 'blood_urea']]\n",
    "rd_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction 1 - no CKD:\n",
    "prediction = rd_clf.predict([[1.025, 15.8, 1.1, 0.0, 53.0, 0, 0, 131.0, 6.1, 18.0]])[0]\n",
    "if prediction:\n",
    "    print('Oops! You have Chronic Kidney Disease.')\n",
    "else:\n",
    "    print(\"Great! You don't have Chronic Kidney Disease.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction 2 - CKD:\n",
    "prediction = rd_clf.predict([[1.020, 15.4, 1.2, 1.0, 44.0, 1, 1, 121.0, 5.2, 36.0]])[0]\n",
    "if prediction:\n",
    "    print('Oops! You have Chronic Kidney Disease.')\n",
    "else:\n",
    "    print(\"Great! You don't have Chronic Kidney Disease.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize and save model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(rd_clf,open(\"CKD.pkl\",\"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "49af8a817c391eb33756880b3f64a0aee7c18f0c1da379cded11e064a517efb9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
